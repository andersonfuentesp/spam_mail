{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CORREO_SPAM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcmM07CDNWjr"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6227cerYIk8"
      },
      "source": [
        "Leemos desde el dataset, ya que es una muestra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Cnf4yPSiNrPg",
        "outputId": "ab89de21-e9f0-4fdc-bfc9-2f85e32f660b"
      },
      "source": [
        "spam_or_ham = pd.read_csv(\"spam.csv\", encoding='latin-1')[[\"v1\", \"v2\"]]\n",
        "spam_or_ham.columns = [\"label\", \"text\"]\n",
        "spam_or_ham.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaDIwdsZYW0s"
      },
      "source": [
        "Contando cuántos son Spam y no spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmoCIawMWYM7",
        "outputId": "fd1db910-378c-403c-8620-0d3d779add72"
      },
      "source": [
        "spam_or_ham[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o9aH0DUYqqy"
      },
      "source": [
        "Con el siguiente método realizamos una optimización. Eliminación de las muestras innecesarias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzNNE1JSWbHh"
      },
      "source": [
        "import string\n",
        "punctuation = set(string.punctuation)\n",
        "def tokenize(sentence):\n",
        "    tokens = []\n",
        "    for token in sentence.split():\n",
        "        new_token = []\n",
        "        for character in token:\n",
        "            if character not in punctuation:\n",
        "                new_token.append(character.lower())\n",
        "        if new_token:\n",
        "            tokens.append(\"\".join(new_token))\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZf6Eik3YtvC"
      },
      "source": [
        "Aplicamos el algoritmo de tokenización sobre la muestra con el siguiente código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NNMhwBzWeFp",
        "outputId": "f0a7c407-b76e-4823-965c-59de4af35272"
      },
      "source": [
        "spam_or_ham.head()[\"text\"].apply(tokenize)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [go, until, jurong, point, crazy, available, o...\n",
              "1                       [ok, lar, joking, wif, u, oni]\n",
              "2    [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
              "3    [u, dun, say, so, early, hor, u, c, already, t...\n",
              "4    [nah, i, dont, think, he, goes, to, usf, he, l...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOHcswqSZW4-"
      },
      "source": [
        "Vamos a usar la librería scikit-learn a fin de realizar el trabajo pesado del proceso de aprendizaje y de las pruebas. Estamos diciendo qué función tiene que usar para la tokenización y que ésta debe ser binaria, es decir, no importa el número de veces que aparece una palabra, simplemente mirará si aparece o no. Con el siguiente código separamos los datos entre entrenamiento y pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOX-8YM5WieQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "demo_vectorizer = CountVectorizer(\n",
        "    tokenizer = tokenize,\n",
        "    binary = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i1iFvPtZxtr"
      },
      "source": [
        "La salida de bloque es:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9s_Zua5WkwK",
        "outputId": "217a88df-8364-4704-a278-4fab2488b931"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(spam_or_ham[\"text\"], spam_or_ham[\"label\"], stratify=spam_or_ham[\"label\"])\n",
        "print(f\"Training examples: {len(train_text)}, testing examples {len(test_text)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples: 4179, testing examples 1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31j4-V-_Z77Z"
      },
      "source": [
        "Nos quedaron 4179 ejemplos para entrenamiento y 1393 ejemplos para pruebas. Creamos un nuevo vectorizador, desde cero, en el que solamente vamos a usar los datos de entrenamiento, no los datos de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFW9ukyuWn9Z"
      },
      "source": [
        "real_vectorizer = CountVectorizer(tokenizer = tokenize, binary=True)\n",
        "train_X = real_vectorizer.fit_transform(train_text)\n",
        "test_X = real_vectorizer.transform(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9uqFtHxaOwU"
      },
      "source": [
        "Creamos el nuevo clasificador y usamos el método fit() para procesar los datos, lo que prepara al clasificador para usarlo más adelante. De nuevo, usamos los datos de entrenamiento para prepararlo, no los de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwUQO8zcWt9w",
        "outputId": "4d164fe8-143e-46d9-9f62-96e22a38d189"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "classifier = LinearSVC()\n",
        "classifier.fit(train_X, train_labels)\n",
        "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
        "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
        "          verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRkrg4k8aeBq"
      },
      "source": [
        "El clasificador está listo para trabajar con él, pero antes de ello hay que realizar una operación muy interesante que se basa en predecir la precisión de las clasificaciones que conseguirá. Para ello entra en juego otro método importante del clasificador. Se trata del método predict() que permite realizar finalmente las clasificaciones. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjPUziyPbFrK"
      },
      "source": [
        "Para calcular la precisión usamos los datos de prueba. La función de scikit-learn llamada accuracy_score() nos sirve para calcular la puntuación de manera sencilla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xDbwE3fWxpR",
        "outputId": "cfbb18af-4aca-4f93-b4e3-b0adeb556b8a"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "predicciones = classifier.predict(test_X)\n",
        "accuracy = accuracy_score(test_labels, predicciones)\n",
        "print(f\"Accuracy: {accuracy:.4%}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.2053%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc4ZHyEvbRK9"
      },
      "source": [
        "Insertamos las frases en un arreglo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NhkbXhgWzYm"
      },
      "source": [
        "frases = [\n",
        "  'Are you looking to redesign your website with new modern look and feel?',\n",
        "  'Please send me a confirmation of complete and permanent erasure of the personal data',\n",
        "  'You have been selected to win a FREE suscription to our service',\n",
        "  'We’re contacting you because the webhook endpoint associated with your account in test mode has been failing',\n",
        "  'Confirma tu cuenta de Facebook en el siguiente link',\n",
        "  'You have been selected to participate in a free service'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1rZBV_9bZgz"
      },
      "source": [
        "Las pasamos por nuestro algoritmo de transformación y vectorización, para finalmente recibir las predicciones de clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ojY_rkW3hK"
      },
      "source": [
        "frases_X = real_vectorizer.transform(frases)\n",
        "predicciones = classifier.predict(frases_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60g0qzB9mmnU"
      },
      "source": [
        "Recorremos las predicciones y mostrar lo que el sistema ha sido capaz de interpretar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXS67GM2W-NK",
        "outputId": "b10cc03d-05ca-4b22-cdcd-73654854535a"
      },
      "source": [
        "for text, label in zip(frases, predicciones):\n",
        "  print(f\"{label:5} - {text}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ham   - Are you looking to redesign your website with new modern look and feel?\n",
            "ham   - Please send me a confirmation of complete and permanent erasure of the personal data\n",
            "spam  - You have been selected to win a FREE suscription to our service\n",
            "ham   - We’re contacting you because the webhook endpoint associated with your account in test mode has been failing\n",
            "ham   - Confirma tu cuenta de Facebook en el siguiente link\n",
            "spam  - You have been selected to participate in a free service\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}